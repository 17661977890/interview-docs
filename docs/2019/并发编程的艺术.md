## 并发编程的挑战
### 上下文切换
* CPU通过时间片分配算法来循环执行任务.当前一个任务执行完成后回切换到下一个任务，并且会保存上一个任务的状态，方便下次切换回这个任务时重新加载它的状态。任务从保存栽倒加载的一个过程就是上下文切换，线程过多的下文切换时会导致CPU性能下降，内存飙升等。

### 如何减少上下文切换
减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程

* 无锁并发编程：多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据
* CAS算法：即比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。
* 使用最少线程:避免创建不需要的线程
* 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切

### 死锁
线程死锁是指由于两个或者多个线程互相持有对方所需要的资源，并且的都在等待释放后才能向下执行，所以导致这些线程处于等待状态，无法前往执行。

 **避死锁的几个常见方法** 
* 避免一个线程同时获取多个锁。
* 避免一个线程在锁内同时占用多个资源，尽量保证每个锁占用一个资源。
* 尝试使用定时锁
* 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况

## volatile的应用
volatile是轻量级的synchronized。volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的

 **volatile是如何来保证可见性的** 
* 有volatile修饰的共享变量进行写操作的时候会在多出带lock前缀的汇编代码。
* Lock前缀的指令在多核处理器下会将当前处理器缓存数据写会主内存中（系统内存）,并且会使其它CPU里缓存该内存的地址的数据无效（使每个线程的工作内存的值无效，强制从主内存获取最新的值进行操作）
* 在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。

 **volatile的两条实现原则** 
* Lock前缀指令会引起处理器缓存回写到内存
* 一个处理器的缓存回写到内存会导致其他处理器的缓存无效

## synchronized的实现原理与应用
java中的每一个对象都可以作为锁.具体表现为以下3种形式:
* 对于普通同步方法，锁是当前实例对象
* 对于静态同步方法，锁是当前类的Class对象
* 对于同步方法块，锁是Synchonized括号里配置的对象

 **JVM基于进入和退出Monitor对象来实现方法同步和代码块同步.代码块同步是使用monitorenter和monitorexit指令实现的** 
* `monitorenter`指令是在编译后插入到同步代码块的开始位置,`monitorexit`是插入到方法结束处和异常处。
* JVM保证每个`monitorenter`都有一个对应的`monitorexit`
* 任何对象都有一个`monitor`与之关联，当且一个`monitor`被持有后，它将处于锁定状态。线程执行到`monitorenter`指令时，将会尝试获取对象所对应的`monitor`的所有权，即尝试获得对象的锁

### Java对象头
* synchronized用的锁是存在Java对象头里的。
* 如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。
* 在32位虚拟机中，1字宽等于4字节，即32bit

 **Mark Word** 
* java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位

![](https://images.gitee.com/uploads/images/2019/0225/214827_d3022441_1478371.png)

* Mark Word在运行期间会随着锁标志位的变化而变化

![](https://images.gitee.com/uploads/images/2019/0225/214910_2897414f_1478371.png)

### 锁的升级与对比
* javaSE 1.6中锁一共有四种状态：无锁状态,偏向锁状态，轻量级锁状态，重量级锁状态。
* 这几种状态会随着竞争情况而逐渐升级，锁可以升级但不可以降级，目的是为了提高获得锁和释放锁的效率。

#### 偏向锁 
* 当一个线程访问同步代码块时，会在对象头和栈帧中的锁记录里存储偏向的线程ID，以后该线程进入和退出同步块时，不需要执行CAS操作来加锁和解锁，只需要简单的测试下对象头的Mark Word是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已获取到锁。 
* 如果测试失败，则需要在测试下Mark Word中偏向锁的表示是否设置为1（表示当前是偏向锁）；如果没有设置，则使用CAS竞争；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

 **偏向锁的撤销** 
* 偏向锁使用了一种等到竞争出现才释放锁的机制，当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁
* 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）
* 它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否存活，如果线程处于不活动状态，则会将对象头设置成无所状态
* 如果线程仍然活着，拥有偏向锁的线程会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程

![偏向锁的初始化流程](https://images.gitee.com/uploads/images/2019/0226/135105_4de8898d_1478371.png)

 **关闭偏向锁** 
* 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：`-XX:BiasedLockingStartupDelay=0`。
* 可以通过JVM参数关闭偏向锁：`-XX:-UseBiasedLocking=false`，那么程序默认会进入轻量级锁状态

#### 轻量级锁

 **轻量级锁加锁** 
* 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间,并将对象头中的Mark Word复制到锁记录中(官方称为`Displaced Mark Word`)
* 然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针
* 如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁

 **轻量级锁解锁** 
* 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头
* 如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁

#### 锁的优缺点对比
* 偏向锁： 加锁和解锁不需要额外的消耗，和执行非同步方法只存在纳秒级的差距。缺点是如果线程间存在锁竞争，会带来额外的锁撤销的消耗。使用与只有一个线程访问同步块
* 轻量级锁：竞争的线程不会阻塞，提高了线程的响应速度。缺点是如果始终得不到锁竞争的线程，使用自旋会消耗CPU。使用于追求响应时间，同步块执行速度非常快
* 重量级锁：线程竞争不使用自旋，不会消耗CPU。缺点是线程阻塞，响应时间慢。使用追求吞吐量，同步块执行时间过长。

## 原子操作的实现原理
* 原子操作意为不可被中断的一个或一系列操作

### 使用总线索保证原子性
* 如果多个处理器同时对共享变量进行读写改操作（比如i++），那吗共享变量就会被多个处理器操作，读写改操作就不是原子的，共享变量的值会和预期的不一致。
* 所谓总线锁就是使用处理器提供的一个LOCK#信号，当一个处理器在总线锁输出此信号时，其它处理器就会被阻塞，该处理器将独占内存。

### 使用缓存锁保证原子性
* 所谓 "缓存锁定“ 是指内存区域如果被锁定在缓存处理器缓存行中，并且Lock操作期间被锁定,那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK#信号，而是修改内存的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会是缓存行无效。

 **以下两种情况不会使用缓存锁定** 
* 当操作的数据不能被缓存在处理器内部，或操作的数据跨域多个缓存行时，则处理器会调用总线锁定。
* 有些处理器不支持缓存锁定。

### java如何实现原子操作
* 使用循环CAS和锁的方式实现原子操作

#### CAS
* JVM中的CAS是利用处理的`cmpxchg`（汇编指令，比较并交换操作数）来实现的

 **CAS实现原子操作的三大问题** 
* ABA问题（CAS操作时需要先检查值是否变化，但是一个值是A接着被改为B 后面又修改为A，CAS操作就会认为他们没有变化。ABA的解决思路是利用版本号）
* 循环时长开销大（自选CAS长时间不成功会增大CPU的开销）
* 只能保证一个共享变量的原子操作。解决思路把多个变量合并为一个变量操作。JDK1.5开始提供了`AtomicReference`保证对象引用之间的原子性，就可以把多个变量放在同一个对象里进行CAS操作

 **使用锁机制保证实现原子操作** 
* JVM内部实现了很多种锁机制，偏向锁，轻量级锁，互斥锁。除了偏向锁，JVM实现锁的方式都是用来 循环CAS。即一个线程想进如同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS的方式退出锁。


## JAVA内存模型

### 内存模型的抽象结构
* 在JAVA中所有的实列域，静态域和数组元素都存储在堆内存中，堆内存在线程之间共享。
* 局部变量，方法定义参数和异常处理参数不会在线程之间共享，他们不会有内存可见性问题，也不受内存模型的影响。
* JAVA线程之间的通讯是通过内存模型控制的，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

![](https://images.gitee.com/uploads/images/2019/0227/214029_42e4dc01_1478371.png)

### 从源代码到指令序列的重排序
执行程序时，编译器和处理器常常会对指令做重排序。分为一下三类：
* 编译器优化的重排序。编译器在不改变单线程程序语意的前提下，可以重新安排代码的执行顺序。
* 指令级并行的重排序。现代处理器使用了指令级并行技术，将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
* 内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。


### happens-before简介
* 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系
* 两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！ happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前

 **happens-before规则如下:** 
* 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作
* 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁
* volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读
* 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C
* 线程启动规则。Thread对象的start()方法先行发生于此线程的每个一个动作；
* 程中断规则。对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
* 线程终结规则。线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
* 对象终结规则。一个对象的初始化完成先行发生于他的finalize()方法的开始；

### as-if-serial语义
* `as-if-serial`语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守`as-if-serial`语义。
* 为了遵守`as-if-serial`语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果
* 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是`as-if-serial`语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。

###  顺序一致性
* 如果程序是正确同步的，程序的执行将具有顺序一致性.即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。这里的同步是指广义上的同步，包括对常用同步原语（`synchronized`、`volatile`和`final`）的正确使用。

#### 顺序一致性内存模型
顺序一致性内存模型有两大特性
* 一个线程中的所有操作必须按照程序的顺序来执行
* (不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。

![](https://images.gitee.com/uploads/images/2019/0228/163954_bdbfe46a_1478371.png)

在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作

![](https://images.gitee.com/uploads/images/2019/0228/171332_59cb768f_1478371.png)

* 现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的

![没有做同步的顺序一致性模型](https://images.gitee.com/uploads/images/2019/0228/171804_f146bd66_1478371.png)

* 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程A和B看到的执行顺序都是：B1→A1→A2→B2→A3→B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见
* 但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致

#### 同步程序的顺序一致性效果

![](https://images.gitee.com/uploads/images/2019/0228/172226_59d1bb7b_1478371.png)

* 顺序一致性模型中，所有操作完全按程序的顺序串行执行
* 而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）
* JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图
* 虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果

![](https://images.gitee.com/uploads/images/2019/0228/172436_97f9ce1f_1478371.png)

#### 未同步程序的执行特性
未同步程序在JMM中的执行时，整体上是无序的，其执行结果无法预知。未同步程序在两个模型中的执行特性有如下几个差异
* 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）
* 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序
* JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性

第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（Bus Transaction）

 **总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其他的处理器和I/O设备执行内存的读/写** 

![总线的工作机制](https://images.gitee.com/uploads/images/2019/0228/173122_394bb3cc_1478371.png)

* 从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性（即任意读操作必须要在单个读事务中执行）

### volatile的内存语义
* 理解volatile特性的一个好方法是把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步
* 一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。

 **volatile写-读建立的happens-before关系** 
* 从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果
* volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义

![](https://images.gitee.com/uploads/images/2019/0228/174746_41a3626a_1478371.png)

假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens-before规则，这个过程建立的happens-before关系可以分为3类：

* 根据程序次序规则，1 happens-before 2;3 happens-before 4。
* 根据volatile规则，2 happens-before 3
* 根据happens-before的传递性规则，1 happens-before 4

 **volatile写-读的内存语义** 
* 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存
* 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量到本地内存中

下面对volatile写和volatile读的内存语义做个总：

* 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息
* 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息
* 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息

 **volatile内存语义的实现** 
* 重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型

![](https://images.gitee.com/uploads/images/2019/0228/175343_1e9e3325_1478371.png)

* 当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作
* 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后
* 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。
* 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序

为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序

* 在每个volatile写操作的前面插入一个StoreStore屏障
* 在每个volatile写操作的后面插入一个StoreLoad屏障
* 在每个volatile读操作的后面插入一个LoadLoad屏障
* 在每个volatile读操作的后面插入一个LoadStore屏障

![](https://images.gitee.com/uploads/images/2019/0228/180843_1a33eeae_1478371.png)

* 图3-20中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序
* LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序

### 锁的内存语义
* 锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。

![](https://images.gitee.com/uploads/images/2019/0301/180815_751a262d_1478371.png)

假设线程A执行writer()方法，随后线程B执行reader()方法。根据happens-before规则，这个过程包含的happens-before关系可以分为3类。

* 根据程序次序规则，1 happens-before 2,2 happens-before 3;4 happens-before 5,5 happensbefore 6
* 根据监视器锁规则，3 happens-before 4
* 根据happens-before的传递性，2 happens-before 5

当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中

![](https://images.gitee.com/uploads/images/2019/0301/181049_cfcb7f3c_1478371.png)


当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量

![](https://images.gitee.com/uploads/images/2019/0301/181111_668c0317_1478371.png)

对比锁释放-获取的内存语义与volatile写-读的内存语义可以看出：锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。

 **下面对锁释放和锁获取的内存语义做个总结** 
* 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息
* 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息
* 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息

#### 锁内存语义的实现
借助ReentrantLock的源代码，来分析锁内存语义的具体实现机制。

![](https://images.gitee.com/uploads/images/2019/0301/184148_dd8e4a3e_1478371.png)

* ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（本文简称之为AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态
* ReentrantLock分为公平锁和非公平锁
* 公平锁和非公平锁释放时，最后都要写一个volatile变量state
* 公平锁获取时，首先会去读volatile变量
* 非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存语义

 **锁释放-获取的内存语义的实现至少有下面两种方式** 
* 利用volatile变量的写-读所具有的内存语义
* 利用CAS所附带的volatile读和volatile写的内存语义

#### concurrent包的实现

